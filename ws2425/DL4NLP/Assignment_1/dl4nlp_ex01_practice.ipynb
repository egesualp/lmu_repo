{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch padded sequences shape: torch.Size([3, 10])\n",
      "Padded sequences: tensor([[1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "Labels: tensor([0, 1, 2])\n",
      "Batch lengths: [10, 10, 10]\n",
      "----\n",
      "Batch padded sequences shape: torch.Size([3, 25])\n",
      "Padded sequences: tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1.]])\n",
      "Labels: tensor([3, 4, 5])\n",
      "Batch lengths: [25, 25, 25]\n",
      "----\n",
      "Batch padded sequences shape: torch.Size([3, 40])\n",
      "Padded sequences: tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
      "         0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1.]])\n",
      "Labels: tensor([6, 7, 8])\n",
      "Batch lengths: [40, 40, 40]\n",
      "----\n",
      "Batch padded sequences shape: torch.Size([2, 50])\n",
      "Padded sequences: tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "Labels: tensor([ 9, 10])\n",
      "Batch lengths: [50, 50]\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, Sampler, BatchSampler\n",
    "import random\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# Define a simple dataset class for demonstration\n",
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, seq_lengths):\n",
    "        # Generate sequences with specified lengths\n",
    "        self.data = [torch.ones(length) for length in seq_lengths]\n",
    "        self.labels = list(range(len(seq_lengths)))  # Dummy labels for indexing\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "# Define the GroupedSampler class\n",
    "class GroupedSampler(Sampler):\n",
    "    def __init__(self, seqs, batch_size):\n",
    "        self.seqs = seqs\n",
    "        self.batch_size = batch_size\n",
    "        self.index_length_pairs = [(i, len(seq)) for i, seq in enumerate(self.seqs)]\n",
    "\n",
    "    def __iter__(self):\n",
    "        random.shuffle(self.index_length_pairs)\n",
    "        \n",
    "        grouped_indices = []\n",
    "        group_size = self.batch_size * 10  # Smaller group size for demonstration\n",
    "        \n",
    "        for i in range(0, len(self.index_length_pairs), group_size):\n",
    "            group = self.index_length_pairs[i:i + group_size]\n",
    "            group_sorted = sorted(group, key=lambda x: x[1])\n",
    "            grouped_indices.extend([idx for idx, _ in group_sorted])\n",
    "        \n",
    "        return iter(grouped_indices)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seqs)\n",
    "\n",
    "# Define a custom collate function for padding sequences in a batch\n",
    "def collate_fn(batch):\n",
    "    sequences, labels = zip(*batch)\n",
    "    sequences_padded = pad_sequence(sequences, batch_first=True, padding_value=0)\n",
    "    return sequences_padded, torch.tensor(labels)\n",
    "\n",
    "# Create a small dataset of varying sequence lengths\n",
    "small_seq_lengths = [5, 7, 10, 15, 20, 25, 30, 35, 40, 45, 50]\n",
    "small_dataset = SimpleDataset(small_seq_lengths)\n",
    "\n",
    "# Initialize GroupedSampler and BatchSampler\n",
    "batch_size = 3\n",
    "small_grouped_sampler = GroupedSampler(small_dataset.data, batch_size)\n",
    "small_batch_sampler = BatchSampler(small_grouped_sampler, batch_size=batch_size, drop_last=False)\n",
    "\n",
    "# DataLoader to fetch batches using small_batch_sampler with custom collate_fn\n",
    "small_dataloader = DataLoader(small_dataset, batch_sampler=small_batch_sampler, collate_fn=collate_fn)\n",
    "\n",
    "# Display batches to illustrate the grouping and padding process\n",
    "for batch in small_dataloader:\n",
    "    sequences_padded, labels = batch\n",
    "    print(\"Batch padded sequences shape:\", sequences_padded.shape)\n",
    "    print(\"Padded sequences:\", sequences_padded)\n",
    "    print(\"Labels:\", labels)\n",
    "    print(\"Batch lengths:\", [len(seq) for seq in sequences_padded])  # Print the padded length for each sequence in batch\n",
    "    print(\"----\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "temp_dl4nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
