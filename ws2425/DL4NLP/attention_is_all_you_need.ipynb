{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention Scores:\n",
      " [[2 1 1 0 1 1]\n",
      " [1 2 1 1 0 2]\n",
      " [1 1 2 1 1 1]\n",
      " [0 1 1 1 0 1]\n",
      " [1 0 1 0 1 0]\n",
      " [1 2 1 1 0 2]]\n",
      "\n",
      "Attention Weights (after softmax):\n",
      " [[0.38360429 0.14112013 0.14112013 0.05191519 0.14112013 0.14112013]\n",
      " [0.11357902 0.30873978 0.11357902 0.11357902 0.04178339 0.30873978]\n",
      " [0.12956251 0.12956251 0.35218743 0.12956251 0.12956251 0.12956251]\n",
      " [0.0776812  0.2111594  0.2111594  0.2111594  0.0776812  0.2111594 ]\n",
      " [0.24368619 0.08964714 0.24368619 0.08964714 0.24368619 0.08964714]\n",
      " [0.11357902 0.30873978 0.11357902 0.11357902 0.04178339 0.30873978]]\n",
      "\n",
      "Output Matrix:\n",
      " [[0.66584455 0.47527558 0.66584455]\n",
      " [0.26894142 0.8446376  0.73105858]\n",
      " [0.61131246 0.74087497 0.38868754]\n",
      " [0.3665218  0.8446376  0.5       ]\n",
      " [0.73105858 0.51262761 0.42298047]\n",
      " [0.26894142 0.8446376  0.73105858]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "\n",
    "# Define embeddings for each word in the sentence \"Your cat is a lovely cat\"\n",
    "embeddings = {\n",
    "    \"Your\": np.array([1, 0, 1]),\n",
    "    \"cat\": np.array([0, 1, 1]),\n",
    "    \"is\": np.array([1, 1, 0]),\n",
    "    \"a\": np.array([0, 1, 0]),\n",
    "    \"lovely\": np.array([1, 0, 0]),\n",
    "}\n",
    "\n",
    "# Create input matrix with embeddings for the sentence\n",
    "input_matrix = np.array([\n",
    "    embeddings[\"Your\"],\n",
    "    embeddings[\"cat\"],\n",
    "    embeddings[\"is\"],\n",
    "    embeddings[\"a\"],\n",
    "    embeddings[\"lovely\"],\n",
    "    embeddings[\"cat\"],  # Repeating \"cat\" at the end\n",
    "])\n",
    "\n",
    "# Step 1: Calculate Attention Scores (Q * K^T)\n",
    "# Since Q = K = input_matrix, we can do a simple dot product of input_matrix with its transpose\n",
    "attention_scores = np.dot(input_matrix, input_matrix.T)\n",
    "print(\"Attention Scores:\\n\", attention_scores)\n",
    "\n",
    "# Step 2: Apply Softmax to get Attention Weights\n",
    "attention_weights = softmax(attention_scores, axis=1)\n",
    "print(\"\\nAttention Weights (after softmax):\\n\", attention_weights)\n",
    "\n",
    "# Step 3: Multiply Attention Weights by the Value (V) Matrix (which is the same as input_matrix here)\n",
    "output = np.dot(attention_weights, input_matrix)\n",
    "print(\"\\nOutput Matrix:\\n\", output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1],\n",
       "       [0, 1, 1],\n",
       "       [1, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 1]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.66584455, 0.47527558, 0.66584455],\n",
       "       [0.26894142, 0.8446376 , 0.73105858],\n",
       "       [0.61131246, 0.74087497, 0.38868754],\n",
       "       [0.3665218 , 0.8446376 , 0.5       ],\n",
       "       [0.73105858, 0.51262761, 0.42298047],\n",
       "       [0.26894142, 0.8446376 , 0.73105858]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvBjk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
